

+++
date = "2025-03-28"
draft = false
title = "kaggleå…¥é—¨ - æ‰‹å†™æ•°å­—è¯†åˆ«å®æˆ˜"
image = "title.jpg"
categories = ["æ·±åº¦å­¦ä¹ "]
tags = ["kaggle","æ¨¡å‹","AI","CNN"]

copyright="ç–é—´å¾’æ³"

+++

# æ·±åº¦å­¦ä¹ å…¥é—¨ - kaggleæ‰‹å†™æ•°å­—è¯†åˆ«å®æˆ˜

**ç›®å½•**

[TOC]

## å¼•è¨€

> **[Kaggle](https://www.aigc.cn/kaggle)**æ˜¯ä¸€ä¸ªåœ¨æ•°æ®ç§‘å­¦é¢†åŸŸæå…·å½±å“åŠ›çš„åœ¨çº¿ç¤¾åŒºå’Œå¹³å°ï¼Œç”±è”åˆåˆ›å§‹äººã€é¦–å¸­æ‰§è¡Œå®˜å®‰ä¸œå°¼Â·é«˜å¾·å¸ƒå¢å§†ï¼ˆAnthony Goldbloomï¼‰äº2010å¹´åœ¨å¢¨å°”æœ¬åˆ›ç«‹ï¼Œ2017å¹´è¢«è°·æ­Œæ¯å…¬å¸Alphabetæ”¶è´­ï¼Œç°ä¸ºGoogle Cloudçš„ä¸€éƒ¨åˆ†ã€‚å®ƒä¸»è¦é¢å‘æ•°æ®ç§‘å­¦å®¶ã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œæ•°æ®åˆ†æå¸ˆç­‰æ•°æ®é¢†åŸŸçš„ä¸“ä¸šäººå£«ï¼Œä¹Ÿå¸å¼•äº†ä¼—å¤šç›¸å…³é¢†åŸŸçˆ±å¥½è€…çš„åŠ å…¥ï¼Œç›®å‰å·²ç»å¸å¼•äº†80ä¸‡åæ•°æ®ç§‘å­¦å®¶çš„å…³æ³¨ã€‚
>
> Kaggleæœ€å¼€å§‹çš„æˆç«‹åˆè¡·æ˜¯æˆä¸ºæ•°æ®ç§‘å­¦çš„ä¼—åŒ…å¹³å°ï¼Œå¯¹äºä¼ä¸šæ¥è¯´ï¼Œå…»ä¸€æ‰¹å·¥ç¨‹å¸ˆæˆæœ¬è¾ƒé«˜ï¼Œé€šè¿‡åœ¨Kaggleå¹³å°ä¸Šè®¾ç½®ä¸€å®šå¥–é‡‘ï¼Œå°†å¾…è§£å†³çš„æ•°æ®é—®é¢˜å‘å¸ƒåˆ°å¹³å°ä¼—åŒ…æ˜¯ä¸€ä¸ªå¾ˆä¸é”™çš„é€‰æ‹©ï¼Œä¼ä¸šåªéœ€è¦æä¾›æ•°æ®é›†ä»¥åŠæƒ³è¦è§£å†³çš„é—®é¢˜ï¼Œæ•°æ®ä¸“å®¶ä»¬å°±ä¼šåœ¨å¹³å°ä¸Šå¸®å¿™è§£ç­” ã€‚ä»æœ¬è´¨ä¸Šæ¥è¯´ï¼ŒKaggleæ˜¯è¿æ¥æ•°æ®éœ€æ±‚æ–¹ä¸æ‹¥æœ‰æ•°æ®å¤„ç†æŠ€èƒ½äººç¾¤çš„æ¡¥æ¢ã€‚

æœ¬ç¯‡åšå®¢å°†ä¼šä»¥ç®€æ˜çš„æ­¥éª¤ï¼Œå¼•å¯¼ä½ é€šè¿‡**[kaggle](https://www.kaggle.com/)**é€æ­¥å®Œæˆä¸€ä¸ªåŸºç¡€çš„**CNN**ï¼ˆConvolutional Neural Networkï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼‰ç”¨äºç»å…¸çš„**Digit Recognizer**ï¼ˆæ‰‹å†™æ•°å­—è¯†åˆ«ï¼Œè¯†åˆ«ç›®æ ‡å›¾ç‰‡å¹¶è¿”å›æ•°å­—ï¼‰é¡¹ç›®ï¼Œå¹¶æäº¤åˆ°æ¯”èµ›ä¸­ï¼Œå¹¶åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ä»‹ç»æ¶‰åŠçš„ç›¸å…³æ·±åº¦å­¦ä¹ çŸ¥è¯†ï¼Œä¿è¯0åŸºç¡€è¯»è€…ä¹Ÿèƒ½è·Ÿéšå®Œæˆå¹¶äº†è§£å…³äºæ·±åº¦å­¦ä¹ å·¥ä½œçš„åŸºç¡€æµç¨‹ã€‚

åœ¨è¿›è¡Œåç»­æ­¥éª¤å‰ï¼Œä½ æœ€å¥½å…ˆæ³¨å†Œä¸€ä¸ª***Kaggle***è´¦å·ã€‚å¦‚æœä½ ä¸ä¼šæ³¨å†Œï¼Œè¯·å‚è€ƒè¿™é‡Œï¼šhttps://blog.csdn.net/weixin_51288849/article/details/130164188 ã€‚

## ç¬¬ä¸€æ­¥ï¼šäº†è§£é¡¹ç›®ä¿¡æ¯

é¦–å…ˆé€šè¿‡è¿™ä¸ªç½‘å€ï¼š[[Digit Recognizer]](https://www.kaggle.com/competitions/digit-recognizer/) æ¥æ‰“å¼€æ¯”èµ›é¡µé¢ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œäº†è§£åˆ°é¡¹ç›®çš„ç›¸å…³ä¿¡æ¯ã€‚

æ³¨æ„ä¸¤ä¸ªæ¨¡å—ï¼š**Overview**ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œäº†è§£åˆ°è¿™ä¸ªé¡¹ç›®çš„ä¸»è¦ä¿¡æ¯ï¼›**Data**ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œäº†è§£åˆ°æ•°æ®é›†çš„æ ¼å¼ã€‚

>  This competition is the perfect introduction to techniques like neural networks using a classic dataset including pre-extracted features.

æ³¨æ„ä¸€ä¸‹æ•°æ®é›†çš„æ ¼å¼ï¼Œåœ¨å¤„ç†æ•°æ®é›†çš„æ ¼å¼æ—¶è¦ç”¨ï¼š

> The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.
>
> Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.
>
> The training data set, (train.csv), has 785 columns. The first column, called "label", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.
>
> Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).
>
> For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.	

é€šè¿‡è¿™æ®µè¯ï¼Œæˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°ï¼Œç¬¬ä¸€æ®µæ˜¯è®­ç»ƒæ•°æ®é›†çš„çœŸå®æ ‡ç­¾ï¼Œå› æ­¤åœ¨å¤„ç†æ—¶è¦å…ˆåˆ†ç¦»å¼€ã€‚åŒæ—¶ï¼Œæ¯ä¸€åˆ—çš„æ•°æ®æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º784çš„å‘é‡ï¼Œå…¶ä¸­æ¯ä¸€ä¸ªæ•°ä»£è¡¨ä¸€ä¸ªåƒç´ ç‚¹ï¼Œæ„æˆ*28 x 28*çš„å›¾åƒã€‚æ¯ä¸€ä¸ªåƒç´ ç‚¹éƒ½æ˜¯*0 ~ 255*ä¹‹é—´çš„ä¸€ä¸ªæ•°å­—ï¼Œä»£è¡¨è¿™ä¸ªåƒç´ ç‚¹çš„ç°åº¦å€¼ã€‚

å¾—å‡ºè¿™äº›æ¡ä»¶åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹äº†ã€‚

## ç¬¬äºŒæ­¥ï¼šå¤„ç†æ•°æ®

åœ¨åŒç•Œé¢çš„å³ä¸Šè§’ï¼Œæ‰¾åˆ°**Submit Prediction**,ç‚¹é€‰**Note Book**å¹¶ç‚¹é€‰**Create Notebook**ä»¥åˆ›å»ºè®°äº‹æœ¬ã€‚

æ¥ä¸‹æ¥å°±æ˜¯æ­£å¼çš„ä»£ç ç¯èŠ‚ã€‚åœ¨è¿›è¡Œåç»­æ“ä½œå‰ï¼Œå…ˆå¯¼å…¥ä¸€äº›å¿…è¦çš„åº“ï¼Œå…·ä½“ä½œç”¨åœ¨æ³¨é‡Šé‡Œè¯´æ˜ï¼š

```python
# ========== ç¬¬1éƒ¨åˆ†ï¼šå¯¼å…¥åº“ ==========
import numpy as np          # æ•°å­¦è®¡ç®—
import pandas as pd         # æ•°æ®å¤„ç†
import matplotlib.pyplot as plt  # ç»˜å›¾
from sklearn.model_selection import train_test_split  # æ•°æ®æ‹†åˆ†
import tensorflow as tf     # æ·±åº¦å­¦ä¹ æ¡†æ¶
from tensorflow.keras.models import Sequential  # é¡ºåºæ¨¡å‹
from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout, Input,MaxPooling2D  # å„å±‚ç»„ä»¶

# è§£é‡Šï¼šè¿™é‡Œå¯¼å…¥æ‰€æœ‰éœ€è¦çš„å·¥å…·åŒ…ï¼Œå°±åƒåšèœå‰å‡†å¤‡å¥½é£Ÿæå’Œå¨å…·
```

åœ¨**Notebook**çš„ä»£ç å—ä¸­è¾“å…¥ä»¥ä¸Šä»£ç ï¼Œç„¶åè¿è¡Œå³å¯ã€‚

é¦–å…ˆï¼Œè¦è½½å…¥æ¯”èµ›ä¸­æ‰€ç”¨åˆ°çš„æ•°æ®é›†ã€‚å¼€ä¸€ä¸ªæ–°çš„ä»£ç å—ï¼Œç„¶åè¾“å…¥ä»¥ä¸‹ä»£ç 

```python
train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv') #åŠ è½½è®­ç»ƒé›†
test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')  #åŠ è½½æµ‹è¯•é›†
```

ä»¥ä¸Šä¸¤è¡Œå°†æ•°æ®é›†ä¸­çš„æ•°æ®è¯»å‡ºï¼Œå¹¶è½¬åŒ–ä¸º`pandas DataFrame`æ ¼å¼ã€‚ä¸ºäº†æ–¹ä¾¿åç»­å¤„ç†ï¼Œæˆ‘ä»¬è¦å°†å…¶è½¬åŒ–ä¸º`NumPy æ•°ç»„`æ ¼å¼ã€‚åŒæ—¶ï¼Œè¦å°†è®­ç»ƒé›†æ‹†åˆ†ä¸º**ç‰¹å¾å’Œæ ‡ç­¾**ä¸¤ä¸ªéƒ¨åˆ†ï¼š

```python
X_train = train_data.drop('label', axis=1).values  # å»æ‰æ ‡ç­¾åˆ—ï¼Œä¿ç•™åƒç´ å€¼
y_train = train_data['label'].values               # åªå–æ ‡ç­¾åˆ—
X_test = test_data.values                          # æµ‹è¯•é›†æ²¡æœ‰æ ‡ç­¾
```

æ¥ä¸‹æ¥å°±å¯ä»¥æ¥æŸ¥çœ‹æ•°æ®çš„æƒ…å†µäº†ï¼š

```python
print("è®­ç»ƒé›†å½¢çŠ¶:", X_train.shape)  # è¾“å‡º (42000, 784) â†’ 42000å¼ å›¾ï¼Œæ¯å›¾28x28=784åƒç´ 
print("æµ‹è¯•é›†å½¢çŠ¶:", X_test.shape)   # è¾“å‡º (28000, 784)
```

åˆ°è¿™ä¸€æ­¥åªæ˜¯è¯»å‡ºäº†æ•°æ®ã€‚æ¥ä¸‹æ¥è¦å¯¹æ•°æ®è¿›è¡Œä¸€å®šçš„å¤„ç†ï¼š

```python
# å½’ä¸€åŒ–ï¼šå°†0-255çš„åƒç´ å€¼ç¼©æ”¾åˆ°0-1ä¹‹é—´ï¼ˆç±»ä¼¼æŠŠé£Ÿæç»Ÿä¸€åˆ‡å—å¤§å°ï¼‰
X_train = X_train / 255.0
X_test = X_test / 255.0

# è°ƒæ•´å½¢çŠ¶ï¼šå°†784çš„ä¸€ç»´æ•°æ®è½¬ä¸º28x28çš„äºŒç»´å›¾åƒï¼ˆæ¢å¤å›¾ç‰‡åŸè²Œï¼‰
# -1è¡¨ç¤ºè‡ªåŠ¨è®¡ç®—æ ·æœ¬æ•°é‡ï¼Œ1è¡¨ç¤ºå•é€šé“ï¼ˆç°åº¦å›¾ï¼‰
X_train = X_train.reshape(-1, 28, 28, 1)
X_test = X_test.reshape(-1, 28, 28, 1)

# åˆ’åˆ†éªŒè¯é›†ï¼šä»è®­ç»ƒé›†ä¸­æ‹¿å‡º20%ä½œä¸ºéªŒè¯ï¼ˆç±»ä¼¼ç•™å‡ºä¸€éƒ¨åˆ†é£Ÿæè¯•èœï¼‰
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)
#æ³¨ï¼šåœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¸­ï¼ŒéªŒè¯é›†ï¼ˆValidation Setï¼‰æ˜¯ç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½å’ŒæŒ‡å¯¼æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„ä¸€ä¸ªæ•°æ®é›†ã€‚
```

åˆ°è¿™ä¸€æ­¥ä¸ºæ­¢ï¼Œæ•°æ®å°±å…¨éƒ¨å¤„ç†å¥½äº†ï¼Œåé¢å°±ä¸ç”¨å†åŠ¨äº†ã€‚ï¼ˆæ³¨æ„ä¸è¦é‡å¤è¿è¡Œï¼‰

## ç¬¬ä¸‰æ­¥ï¼šè®¾ç«‹æ¨¡å‹

å¯¹äºè¿™æ ·ä¸€ä¸ªå›¾åƒè¯†åˆ«çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬é‡‡ç”¨**CNN**æ¨¡å‹ã€‚

> å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¸»è¦ç”¨äºå¤„ç†å…·æœ‰ç½‘æ ¼ç»“æ„çš„æ•°æ®ï¼Œå¦‚å›¾åƒã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å·ç§¯å±‚æå–å±€éƒ¨ç‰¹å¾ï¼Œåˆ©ç”¨æ± åŒ–å±‚è¿›è¡Œç‰¹å¾é™ç»´ï¼Œæœ€åé€šè¿‡å…¨è¿æ¥å±‚è¿›è¡Œåˆ†ç±»æˆ–å›å½’ã€‚CNNå…·æœ‰è‡ªåŠ¨ç‰¹å¾æå–ã€å‚æ•°å…±äº«å’Œå±€éƒ¨æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¿æ³›åº”ç”¨äºå›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹å’Œè§†é¢‘åˆ†æç­‰é¢†åŸŸã€‚

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥å‚è€ƒç»å…¸çš„**LeNet-5**æ¨¡å‹ï¼š

![LeNet-5](Image1.png)

æˆ‘ä»¬é€šè¿‡`Sequential`æ¨¡å—æ¥æ­å»ºæ¨¡å‹ï¼Œå¹¶å¯¹åŸå§‹çš„LeNet-5åšå‡ºä¸€å®šçš„æ”¹è¿›ï¼š

```python
model = Sequential([
    # è¾“å…¥å±‚ï¼šæ¥å—28x28åƒç´ çš„ç°åº¦å›¾åƒï¼ˆé€šé“æ•°ä¸º1ï¼‰
    Input((28, 28, 1)),  # ä¿®æ­£è¾“å…¥å½¢çŠ¶

    # ç¬¬ä¸€å·ç§¯å±‚ï¼šæå–ä½çº§ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€è§’ç‚¹ç­‰ï¼‰
    # ä½¿ç”¨6ä¸ª5x5å·ç§¯æ ¸ï¼Œè¾“å‡º24x24x6çš„ç‰¹å¾å›¾ï¼ˆæ— å¡«å……æ—¶è®¡ç®—ï¼š(28-5+1)=24ï¼‰
    Conv2D(6, (5,5), activation='sigmoid', padding='valid'),  # æ˜ç¡®æŒ‡å®špaddingæ–¹å¼

    # å¹³å‡æ± åŒ–å±‚ï¼šé™ç»´å¹¶å¹³æ»‘ç‰¹å¾å“åº”
    # 2x2çª—å£è®¡ç®—å‡å€¼ï¼Œè¾“å‡º12x12x6çš„ç‰¹å¾å›¾ï¼ˆ24/2=12ï¼‰
    AveragePooling2D((2,2)),

    # ç¬¬äºŒå·ç§¯å±‚ï¼šç»„åˆä½çº§ç‰¹å¾ä¸ºä¸­çº§ç‰¹å¾ï¼ˆçº¹ç†ã€éƒ¨ä»¶ç­‰ï¼‰
    # 16ä¸ª5x5å·ç§¯æ ¸ï¼Œè¾“å‡º8x8x16çš„ç‰¹å¾å›¾ï¼ˆè®¡ç®—ï¼š(12-5+1)=8ï¼‰
    Conv2D(16, (5,5), activation='relu', padding='valid'), # LeNetåŸè®ºæ–‡ä½¿ç”¨sigmoid

    # æœ€å¤§æ± åŒ–å±‚ï¼šä¿ç•™æœ€æ˜¾è‘—ç‰¹å¾å¹¶é™ç»´
    # 2x2çª—å£å–æœ€å¤§å€¼ï¼Œè¾“å‡º4x4x16çš„ç‰¹å¾å›¾ï¼ˆ8/2=4ï¼‰
    MaxPool2D((2,2)),

    # å±•å¹³å±‚ï¼šå°†ä¸‰ç»´ç‰¹å¾è½¬æ¢ä¸ºä¸€ç»´å‘é‡
    Flatten(),  # ä¿®æ­£å±•å¹³ç»´åº¦è¯´æ˜

    # ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼šå…¨å±€ç‰¹å¾æ•´åˆ
    # è¾“å…¥ç»´åº¦è‡ªåŠ¨ç»§æ‰¿å±•å¹³å±‚çš„256ï¼Œè¾“å‡º120ç»´
    Dense(120, activation='relu'),  # æ— éœ€æŒ‡å®šinput_dimï¼Œè‡ªåŠ¨è¿æ¥

    # Dropoutå±‚ï¼šéšæœºæ–­å¼€30%ç¥ç»å…ƒè¿æ¥
    Dropout(0.3),

    # ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼šè¿›ä¸€æ­¥ç‰¹å¾ç²¾ç‚¼
    Dense(84, activation='relu'),  # è¾“å…¥è‡ªåŠ¨ç»§æ‰¿å‰å±‚çš„120

    # è¾“å‡ºå±‚ï¼šç”Ÿæˆç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ
    Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',  # è‡ªé€‚åº”å­¦ä¹ ç‡çš„ä¼˜åŒ–å™¨
    loss='sparse_categorical_crossentropy',  # å¤šåˆ†ç±»æŸå¤±å‡½æ•°
    metrics=['accuracy']  # ç›‘æ§å‡†ç¡®ç‡
)
```

é€šè¿‡ä»¥ä¸Šä»£ç æˆ‘ä»¬å°±å®šä¹‰å¥½äº†æ¨¡å‹ã€‚è¿™æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹ä»£ç æ¥æŸ¥çœ‹æ¨¡å‹ç»“æ„ï¼š

```python
model.summary() 
```

## ç¬¬å››æ­¥ï¼šè®­ç»ƒæ¨¡å‹

æˆ‘ä»¬é€šè¿‡**`model.fit`**æ–¹æ³•æ¥è®­ç»ƒæ¨¡å‹ã€‚åœ¨æœ¬æ¬¡è®­ç»ƒä¸­ï¼Œè°ƒç”¨è¯¥æ–¹æ³•ï¼Œæˆ‘ä»¬æŒ‡å®šä»¥ä¸‹å‚æ•°ï¼š

- #### **`x`**

  - **å«ä¹‰**ï¼šè®­ç»ƒæ•°æ®çš„ç‰¹å¾é›†ã€‚
  - **ç±»å‹**ï¼šå¯ä»¥æ˜¯ NumPy æ•°ç»„ã€TensorFlow å¼ é‡ã€Python ç”Ÿæˆå™¨ï¼ˆç”¨äºç”Ÿæˆæ•°æ®ï¼‰æˆ– TensorFlow æ•°æ®é›†å¯¹è±¡ï¼ˆ`tf.data.Dataset`ï¼‰ã€‚

- #### **`y`**

  - **å«ä¹‰**ï¼šè®­ç»ƒæ•°æ®çš„æ ‡ç­¾é›†ã€‚
  - **ç±»å‹**ï¼šå¯ä»¥æ˜¯ NumPy æ•°ç»„ã€TensorFlow å¼ é‡æˆ– Python ç”Ÿæˆå™¨ï¼ˆä¸ `x` é…åˆä½¿ç”¨ï¼‰ã€‚

- #### **`validation_data`**

  - **å«ä¹‰**ï¼šç”¨äºéªŒè¯æ¨¡å‹æ€§èƒ½çš„æ•°æ®é›†ã€‚æ¨¡å‹ä¼šåœ¨æ¯ä¸ª epoch ç»“æŸåï¼Œåœ¨éªŒè¯æ•°æ®ä¸Šè¯„ä¼°æ€§èƒ½ã€‚
  - **ç±»å‹**ï¼šå…ƒç»„ `(X_val, y_val)`ï¼Œå…¶ä¸­ `X_val` å’Œ `y_val` åˆ†åˆ«æ˜¯éªŒè¯æ•°æ®çš„ç‰¹å¾å’Œæ ‡ç­¾ã€‚

- #### **`epochs`**

  - **å«ä¹‰**ï¼šè®­ç»ƒçš„æ€»è¿­ä»£æ¬¡æ•°ã€‚æ¯ä¸ª epoch è¡¨ç¤ºæ¨¡å‹å®Œæ•´éå†ä¸€æ¬¡è®­ç»ƒæ•°æ®ã€‚
  - **ç±»å‹**ï¼šæ•´æ•°ã€‚

- #### **`batch_size`**

  - **å«ä¹‰**ï¼šæ¯æ¬¡ä¼ é€’ç»™æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„æ ·æœ¬æ•°é‡ã€‚è®­ç»ƒæ•°æ®ä¼šè¢«åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯ä¸ªæ‰¹æ¬¡åŒ…å« `batch_size` ä¸ªæ ·æœ¬ã€‚
  - **ç±»å‹**ï¼šæ•´æ•°æˆ– `None`ã€‚å¦‚æœä¸º `None`ï¼Œåˆ™è¡¨ç¤ºä½¿ç”¨æ•´ä¸ªæ•°æ®é›†ä½œä¸ºä¸€ä¸ªæ‰¹æ¬¡ã€‚

ä»£ç å¦‚ä¸‹ï¼š

```python
# å¼€å§‹è®­ç»ƒï¼ˆåƒå¨å¸ˆå¼€ç«ç‚’èœï¼‰
history = model.fit(
    X_train,          # è®­ç»ƒæ•°æ®
    y_train,          # è®­ç»ƒæ ‡ç­¾
    epochs=10,        # æ•´ä¸ªæ•°æ®é›†è®­ç»ƒ10é
    batch_size=32,    # æ¯æ¬¡ç”¨32ä¸ªæ ·æœ¬è®¡ç®—æ¢¯åº¦
    validation_data=(X_val, y_val)  # æ¯è½®ç»“æŸåç”¨éªŒè¯é›†è¯„ä¼°
)
```

è¿è¡Œåéœ€è¦ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œç­‰å¾…è®¡ç®—å®Œæˆã€‚

å®é™…è¿è¡Œæ—¶ï¼Œè¾“å‡ºå¤§æ¦‚å¦‚ä¸‹ï¼š

```python
Epoch 1/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 3ms/step - accuracy: 0.5975 - loss: 1.1617 - val_accuracy: 0.9371 - val_loss: 0.1985
Epoch 2/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9326 - loss: 0.2124 - val_accuracy: 0.9545 - val_loss: 0.1416
Epoch 3/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9513 - loss: 0.1531 - val_accuracy: 0.9664 - val_loss: 0.1066
Epoch 4/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9634 - loss: 0.1201 - val_accuracy: 0.9702 - val_loss: 0.0945
Epoch 5/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9666 - loss: 0.1064 - val_accuracy: 0.9711 - val_loss: 0.0927
Epoch 6/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9684 - loss: 0.1011 - val_accuracy: 0.9750 - val_loss: 0.0819
Epoch 7/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9745 - loss: 0.0855 - val_accuracy: 0.9739 - val_loss: 0.0850
Epoch 8/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9725 - loss: 0.0860 - val_accuracy: 0.9779 - val_loss: 0.0735
Epoch 9/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9773 - loss: 0.0700 - val_accuracy: 0.9779 - val_loss: 0.0751
Epoch 10/10
1050/1050 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 2ms/step - accuracy: 0.9775 - loss: 0.0718 - val_accuracy: 0.9758 - val_loss: 0.0809
```

å½“çœ‹åˆ°`Epoch 10/10`å®Œæˆåï¼Œå°±å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥äº†ã€‚

## ç¬¬äº”æ­¥ï¼šè¯„ä¼°æ¨¡å‹

å®Œæˆå¯¹æ¨¡å‹çš„è®­ç»ƒåï¼Œæˆ‘ä»¬é€šè¿‡æŠ˜çº¿å›¾ç»Ÿè®¡æ¨¡å‹çš„æ•ˆæœï¼š

```python
# ç»˜åˆ¶è®­ç»ƒæ›²çº¿ï¼ˆè§‚å¯Ÿæ˜¯å¦è¿‡æ‹Ÿåˆï¼‰
plt.figure(figsize=(12,4))

# å‡†ç¡®ç‡æ›²çº¿
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='è®­ç»ƒé›†')
plt.plot(history.history['val_accuracy'], label='éªŒè¯é›†')
plt.legend()
plt.title('å‡†ç¡®ç‡')

# æŸå¤±æ›²çº¿
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='è®­ç»ƒé›†')
plt.plot(history.history['val_loss'], label='éªŒè¯é›†')
plt.legend()
plt.title('æŸå¤±å€¼')
plt.show()

# éªŒè¯é›†æœ€ç»ˆè¯„ä¼°
val_loss, val_acc = model.evaluate(X_val, y_val)
print(f"éªŒè¯é›†å‡†ç¡®ç‡: {val_acc*100:.2f}%")
```

è¿è¡Œå¥½åçš„å›¾åƒå¤§è‡´å¦‚ä¸‹ï¼š

![LeNet-5](Image2.png)

è¿™æ„å‘³ç€æˆ‘ä»¬å·²ç»å–å¾—äº†å¯ä»¥ä½¿ç”¨çš„æ¨¡å‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±è¦ç”¨è¿™ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹æ¥å¯¹æµ‹è¯•é›†è¿›è¡Œ**é¢„æµ‹**ï¼ˆPredictï¼‰ã€‚

## ç¬¬å…­æ­¥ï¼šé¢„æµ‹æ•°æ®

é€šè¿‡æˆ‘ä»¬å…ˆå‰è®­ç»ƒçš„æ¨¡å‹ï¼Œç»™å®šä¸€ç»„å›¾ç‰‡ï¼Œå…¶ä¼šç”Ÿæˆä¸€ä¸ª`(æ ·æœ¬æ•°, 10)`çš„æ¦‚ç‡çŸ©é˜µã€‚çŸ©é˜µçš„æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªå›¾ç‰‡çš„æ¦‚ç‡å‘é‡ã€‚å‘é‡é•¿åº¦ä¸º**10**,åˆ†åˆ«å¯¹åº”è¯¥å›¾ç‰‡ä¸º**[0 - 9]**ä¸­å“ªä¸ªæ•°å­—çš„æ¦‚ç‡ã€‚

è¦è¿›è¡Œé¢„æµ‹ï¼Œåªéœ€è¦è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

```python
predictions = model.predict(X_test) 
```

å¦‚æœä½ æƒ³çš„è¯ï¼Œå¯ä»¥åœ¨æ­¤é€šè¿‡ä»¥ä¸‹ä»£ç æ¥æŸ¥çœ‹é¢„æµ‹ç»“æœçš„å±æ€§ï¼š

```python
print(predictions)
print(predictions.shape)
```

ä¸ºäº†å°†æ¦‚ç‡è½¬åŒ–ä¸ºæˆ‘ä»¬éœ€è¦çš„æ ‡ç­¾ï¼Œæˆ‘ä»¬åªéœ€è¦å–å‡ºæ¯ä¸€è¡Œä¸­æ¦‚ç‡æœ€å¤§çš„é‚£ä¸€é¡¹å³å¯ï¼Œæˆ‘ä»¬é€šè¿‡`numpy`çš„`argmax`æ–¹æ³•æ¥å®ç°è¿™ä¸€ç‚¹ï¼š

```python
predicted_labels = np.argmax(predictions, axis=1) # æ²¿ç¬¬ä¸€ä¸ªè½´ï¼ˆè¡Œæ–¹å‘ï¼‰å–æœ€å¤§å€¼ç´¢å¼•
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡`pandas`ç±»æ¥åˆ›å»ºæäº¤æ‰€éœ€çš„è¡¨æ ¼ã€‚ç”±é¢˜ç›®ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“æäº¤çš„è¡¨æ ¼æ ¼å¼æ˜¯ä¸€ä¸ªä¸¤åˆ—çš„è¡¨æ ¼ï¼Œå…¶ä¸­ç¬¬ä¸€åˆ—æ˜¯`ä»1å¼€å§‹è®¡æ•°çš„æœ‰åºæ•°åˆ—`ï¼Œä»£è¡¨å›¾åƒçš„ç¼–å·ï¼›ç¬¬äºŒåˆ—æ˜¯é¢„æµ‹çš„æ ‡ç­¾ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦ç”Ÿæˆä¸€ä¸ª`range(1, len(predicted_labels)+1)`çš„æ•°åˆ—ï¼Œå¹¶é€šè¿‡`pd.DataFrame`æ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªè¡¨æ ¼ï¼Œå…¶ä¸­ç¬¬ä¸€åˆ—ä¸ºæ•°åˆ—ï¼Œç¬¬äºŒåˆ—ä¸ºåˆšæ‰ç”Ÿæˆçš„`predicted_labels`ã€‚

```python
submission = pd.DataFrame({
    'ImageId': range(1, len(predicted_labels)+1),
    'Label': predicted_labels
})
```

æœ€åï¼Œæˆ‘ä»¬éœ€è¦æŠŠå…¶è½¬åŒ–ä¸ºæäº¤æ‰€éœ€çš„`.csv`æ–‡ä»¶ï¼š

```python
submission.to_csv('submission.csv', index=False)
print("æäº¤æ–‡ä»¶å·²ç”Ÿæˆï¼")
```

æ­¤æ—¶ï¼Œæ³¨æ„å³è¾¹çš„ **Output** æ¨¡å—ï¼Œç‚¹å‡»ä¸‹æ‹‰ç®­å¤´ï¼Œæˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°ï¼Œå·²ç»ç”Ÿæˆäº†ä¸€ä¸ªåä¸º`submission.csv`çš„æ–‡ä»¶ï¼Œè¿™å°±æ˜¯ç­‰ä¸‹ç”¨äºæäº¤çš„æ–‡ä»¶ã€‚

## ç¬¬ä¸ƒæ­¥ï¼šæäº¤æ•°æ®

ç‚¹å‡»`submission.csv`å³ä¾§çš„ä¸‰ç‚¹ï¼Œé€‰æ‹©`Download`ã€‚åœ¨ä¸‹è½½å®Œæˆ‘ä»¬æäº¤æ‰€éœ€çš„æ•°æ®åï¼Œå°±å¯ä»¥å‰å¾€æ¯”èµ›ç•Œé¢è¿›è¡Œæäº¤äº†ã€‚

æ‰“å¼€https://www.kaggle.com/competitions/digit-recognizerï¼Œé€‰æ‹©å³ä¸Šè§’çš„**`Submit to Competition`**ã€‚æ‰“å¼€æ‰¾åˆ°åˆšæ‰ä¸‹è½½å¥½çš„æ•°æ®æ–‡ä»¶ï¼Œæ‹–æ‹½åˆ°æŒ‡å®šçš„æ–¹æ¡†å†…ï¼Œå¹¶ç‚¹å‡»***Submit***ã€‚

éšåï¼Œä½ å°±å¯ä»¥åœ¨**Submissions**é‡Œçœ‹åˆ°ä½ çš„æäº¤è®°å½•äº†ã€‚ä½ å¯ä»¥åœ¨å³ä¾§çš„**Public Score**çœ‹åˆ°ä½ çš„å‡†ç¡®ç‡ã€‚ï¼ˆå¤§çº¦ä¼šåœ¨0.98å·¦å³ï¼‰ã€‚

è‡³æ­¤ï¼Œä½ å·²ç»å®Œæˆäº†ä¸€æ¬¡ç®€å•çš„Kaggleæ¯”èµ›ï¼ **Congratulations!ğŸ‰ğŸ‰**

## ç¬¬å…«æ­¥ï¼šä¼˜åŒ–æ€§èƒ½ï¼ˆå¯é€‰ï¼‰

å¦‚æœæƒ³è¦è¿›ä¸€æ­¥å–å¾—å‡†ç¡®ç‡ä¸Šçš„æå‡ï¼Œä½ å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š

------

### **1. å¢åŠ è®­ç»ƒè½®æ•°ï¼ˆEpochsï¼‰**

å°† `epochs=10` è°ƒæ•´ä¸ºæ›´å¤§çš„å€¼ï¼ˆå¦‚ 20-30ï¼‰ï¼Œè®©æ¨¡å‹æ›´å……åˆ†åœ°å­¦ä¹ æ•°æ®ç‰¹å¾ã€‚æ³¨æ„ç›‘æ§éªŒè¯é›†å‡†ç¡®ç‡ï¼Œé¿å…è¿‡æ‹Ÿåˆï¼š

```python
history = model.fit(
    X_train, y_train,
    epochs=30,        # è°ƒæ•´ä¸º30è½®
    batch_size=32,
    validation_data=(X_val, y_val)
```

------

### **2. ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆData Augmentationï¼‰**

é€šè¿‡æ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ç­‰æ“ä½œæ‰©å……è®­ç»ƒæ•°æ®ï¼Œæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼š

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# å®šä¹‰æ•°æ®å¢å¼ºç­–ç•¥
datagen = ImageDataGenerator(
    rotation_range=10,   # éšæœºæ—‹è½¬Â±10åº¦
    zoom_range=0.1,      # éšæœºç¼©æ”¾Â±10%
    width_shift_range=0.1 # æ°´å¹³å¹³ç§»Â±10%
)

# ä½¿ç”¨å¢å¼ºåçš„æ•°æ®è®­ç»ƒæ¨¡å‹
history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    epochs=30,
    validation_data=(X_val, y_val)  # å¿…é¡»åŒ…å«éªŒè¯é›†
)
```

------

### **3. ä¼˜åŒ–æ¨¡å‹ç»“æ„**

- **æ›¿æ¢æ¿€æ´»å‡½æ•°**ï¼šå°† `sigmoid` æ›¿æ¢ä¸º `ReLU` æˆ– `LeakyReLU`ï¼Œä¾‹å¦‚ï¼š

  ```python
  Conv2D(6, (5,5), activation='relu', padding='valid')  # ä¿®æ”¹ç¬¬ä¸€å±‚æ¿€æ´»å‡½æ•°
  ```

- **å¢åŠ ç½‘ç»œæ·±åº¦**ï¼šæ·»åŠ æ›´å¤šå·ç§¯å±‚æˆ–å…¨è¿æ¥å±‚ï¼Œä¾‹å¦‚ï¼š

  ```python
  model.add(Conv2D(32, (3,3), activation='relu', padding='same')  # æ–°å¢å·ç§¯å±‚
  model.add(MaxPool2D((2,2)))
  ```

- **ä½¿ç”¨å…ˆè¿›æ¨¡å‹**ï¼šå°è¯• ResNetã€VGG æˆ– EfficientNet ç­‰ç»“æ„ï¼ˆéœ€è°ƒæ•´è¾“å…¥å°ºå¯¸ï¼‰ã€‚

------

### **4. è°ƒæ•´ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡**

å°è¯•ä¸åŒçš„ä¼˜åŒ–å™¨æˆ–è‡ªå®šä¹‰å­¦ä¹ ç‡ï¼š

```python
from tensorflow.keras.optimizers import Adam

# ä½¿ç”¨æ›´ä½çš„å­¦ä¹ ç‡ï¼ˆå¦‚0.0001ï¼‰
model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

------

### **5. é›†æˆå­¦ä¹ ï¼ˆEnsembleï¼‰**

è®­ç»ƒå¤šä¸ªä¸åŒç»“æ„çš„æ¨¡å‹ï¼Œé€šè¿‡æŠ•ç¥¨æˆ–åŠ æƒå¹³å‡èåˆé¢„æµ‹ç»“æœï¼š

```python
# ç¤ºä¾‹ï¼šè®­ç»ƒ3ä¸ªæ¨¡å‹å¹¶å–ä¼—æ•°
final_pred = np.round((pred1 + pred2 + pred3) / 3).astype(int)
```

------

### **6. è¶…å‚æ•°è°ƒä¼˜**

é€šè¿‡äº¤å‰éªŒè¯ä¼˜åŒ– `batch_size`ã€`Dropout` æ¯”ç‡ç­‰å‚æ•°ï¼š

```python
# ç¤ºä¾‹ï¼šè°ƒæ•´Dropoutæ¯”ä¾‹
model.add(Dropout(0.5))  # ä»0.3è°ƒæ•´ä¸º0.5
```

------

## ç¬¬ä¹æ­¥ï¼šå¯è§†åŒ–æœ¬åœ°è¿è¡Œ

å¦‚æœæƒ³è¦å®é™…çœ‹åˆ°æ¨¡å‹çš„æ•ˆæœï¼Œé‚£ä¹ˆä¸å¦¨æŠŠæ¨¡å‹å¯¼å‡ºåˆ°æœ¬åœ°æ¥å°è¯•ã€‚

åœ¨åˆšæ‰çš„æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œè¿è¡Œä»¥ä¸‹ä»£ç å¯¼å‡ºæ¨¡å‹ï¼š

```python
# ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°
model.save('digit_recognizer_model.h5')
print("æ¨¡å‹å·²ä¿å­˜åˆ°æœ¬åœ°ï¼")
```

ä»¿ç…§å‰æ–‡çš„æ–¹å¼ï¼Œå°†`digit_recognizer_model.h5`ä¸‹è½½ä¸‹æ¥ï¼Œå¯¼å‡ºåˆ°æŒ‡å®šæ–‡ä»¶å¤¹ä¸­ã€‚

å¦‚æœè¿˜æ²¡æœ‰å¯¼å…¥éœ€è¦çš„åº“ï¼Œæ‰“å¼€cmdï¼Œå¯¼å…¥ä»¥ä¸‹åº“ï¼ˆå¦‚æœæ²¡æœ‰å®‰è£…`python`,è¯·å…ˆå‰å¾€å®˜ç½‘å®‰è£… [å®˜ç½‘åœ°å€](https://www.python.org/)ï¼šï¼‰

æ³¨ï¼š`python`ç‰ˆæœ¬å¿…é¡»å¤§äºç­‰äº3.10ï¼Œå¦åˆ™`tensorflow`ä¼šä¸¢å¤±æ¨¡å—ã€‚

```cmd
pip install tensorflow pillow numpy
```

ç„¶åï¼Œåœ¨å¯¼å‡ºçš„æ¨¡å‹æ–‡ä»¶çš„åŒç›®å½•ä¸‹åˆ›å»º`.py`æ–‡ä»¶`digit_recognizer_app.py`ï¼Œæ”¾å…¥ä»¥ä¸‹ä»£ç ï¼š

```python
# å¯¼å…¥å¿…è¦çš„åº“
import tkinter as tk  # ç”¨äºåˆ›å»ºå›¾å½¢ç”¨æˆ·ç•Œé¢
from tkinter import ttk  # ç”¨äºç¾åŒ–ç•Œé¢
from PIL import Image, ImageDraw  # ç”¨äºå›¾åƒå¤„ç†
import numpy as np  # ç”¨äºæ•°å€¼è®¡ç®—
from tensorflow.keras.models import load_model  # ç”¨äºåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
import traceback  # ç”¨äºå¼‚å¸¸å¤„ç†

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
try:
    model = load_model('H:\DeepLearning\DigitalRecognizer\digit_recognizer_model.h5')  # åŠ è½½æ¨¡å‹æ–‡ä»¶
except Exception as e:
    print("æ¨¡å‹åŠ è½½å¤±è´¥:", e)
    traceback.print_exc()

# åˆ›å»ºä¸€ä¸ªç±»ï¼Œç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«åº”ç”¨ç¨‹åº
class DigitRecognizerApp:
    def __init__(self, root):
        # åˆå§‹åŒ–ä¸»çª—å£
        self.root = root
        self.root.title("æ‰‹å†™æ•°å­—è¯†åˆ«")  # è®¾ç½®çª—å£æ ‡é¢˜
        
        # åˆ›å»ºä¸»æ¡†æ¶
        mainframe = ttk.Frame(root, padding="10 10 10 10")
        mainframe.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # åˆ›å»ºä¸€ä¸ªç”»å¸ƒï¼Œç”¨æˆ·å¯ä»¥åœ¨ä¸Šé¢ç»˜åˆ¶æ•°å­—
        self.canvas = tk.Canvas(mainframe, width=280, height=280, bg='white', bd=2, relief='sunken')  # è®¾ç½®ç”»å¸ƒå¤§å°ä¸º280x280ï¼ŒèƒŒæ™¯ä¸ºç™½è‰²ï¼Œæ·»åŠ è¾¹æ¡†
        self.canvas.grid(row=0, column=0, columnspan=3, pady=10)  # å°†ç”»å¸ƒæ”¾ç½®åœ¨çª—å£çš„ç¬¬0è¡Œï¼Œè·¨è¶Šä¸‰åˆ—ï¼Œæ·»åŠ å‚ç›´å¡«å……
        self.canvas.bind("<B1-Motion>", self.paint)  # ç»‘å®šé¼ æ ‡å·¦é”®ç§»åŠ¨äº‹ä»¶ï¼Œè°ƒç”¨paintæ–¹æ³•ç»˜åˆ¶æ•°å­—
        
        # åˆ›å»ºä¸€ä¸ªæŒ‰é’®ï¼Œç”¨äºè§¦å‘é¢„æµ‹æ“ä½œ
        self.predict_button = ttk.Button(mainframe, text="é¢„æµ‹", command=self.predict)  # è®¾ç½®æŒ‰é’®æ–‡æœ¬å’Œç‚¹å‡»äº‹ä»¶
        self.predict_button.grid(row=1, column=0, padx=5, pady=5)  # å°†æŒ‰é’®æ”¾ç½®åœ¨çª—å£çš„ç¬¬1è¡Œï¼Œç¬¬0åˆ—ï¼Œæ·»åŠ å¡«å……
        
        # åˆ›å»ºä¸€ä¸ªæŒ‰é’®ï¼Œç”¨äºæ¸…ç©ºç”»å¸ƒ
        self.clear_button = ttk.Button(mainframe, text="æ¸…ç©º", command=self.clear)  # è®¾ç½®æŒ‰é’®æ–‡æœ¬å’Œç‚¹å‡»äº‹ä»¶
        self.clear_button.grid(row=1, column=1, padx=5, pady=5)  # å°†æŒ‰é’®æ”¾ç½®åœ¨çª—å£çš„ç¬¬1è¡Œï¼Œç¬¬1åˆ—ï¼Œæ·»åŠ å¡«å……
        
        # åˆ›å»ºä¸€ä¸ªæ ‡ç­¾ï¼Œç”¨äºæ˜¾ç¤ºé¢„æµ‹ç»“æœ
        self.result_label = ttk.Label(mainframe, text="é¢„æµ‹ç»“æœï¼š", font=("Helvetica", 16))  # è®¾ç½®åˆå§‹æ–‡æœ¬å’Œå­—ä½“
        self.result_label.grid(row=2, column=0, columnspan=3, pady=10)  # å°†æ ‡ç­¾æ”¾ç½®åœ¨çª—å£çš„ç¬¬2è¡Œï¼Œè·¨è¶Šä¸‰åˆ—ï¼Œæ·»åŠ å‚ç›´å¡«å……
        
        # åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºæ§åˆ¶ç¬”è¿¹ç²—ç»†
        self.pen_size = tk.IntVar(value=18)  # åˆå§‹åŒ–ç¬”è¿¹ç²—ç»†å˜é‡ï¼Œé»˜è®¤å€¼ä¸º10
        self.pen_size_slider = ttk.Scale(mainframe, from_=15, to=40, orient='horizontal', variable=self.pen_size)  # åˆ›å»ºæ»‘å—ï¼ŒèŒƒå›´ä»1åˆ°20
        self.pen_size_slider.grid(row=1, column=2, padx=5, pady=5)  # å°†æ»‘å—æ”¾ç½®åœ¨çª—å£çš„ç¬¬1è¡Œï¼Œç¬¬2åˆ—ï¼Œæ·»åŠ å¡«å……
        self.pen_size_label = ttk.Label(mainframe, text="ç¬”è¿¹ç²—ç»†")  # åˆ›å»ºæ ‡ç­¾ï¼Œæ˜¾ç¤ºæ»‘å—çš„ç”¨é€”
        self.pen_size_label.grid(row=1, column=2, sticky='s')  # å°†æ ‡ç­¾æ”¾ç½®åœ¨æ»‘å—ä¸‹æ–¹

        # åˆå§‹åŒ–ç”»å¸ƒå’Œç»˜å›¾å·¥å…·
        self.clear()  # è°ƒç”¨clearæ–¹æ³•åˆå§‹åŒ–ç”»å¸ƒ

    def paint(self, event):
        # è·å–å½“å‰ç¬”è¿¹ç²—ç»†
        pen_width = self.pen_size.get()

        # ç»˜åˆ¶å½“å‰ç‚¹
        x1, y1 = (event.x - pen_width // 2), (event.y - pen_width // 2)
        x2, y2 = (event.x + pen_width // 2), (event.y + pen_width // 2)
        self.canvas.create_oval(x1, y1, x2, y2, fill="black", width=0)
        self.draw.ellipse([x1, y1, x2, y2], fill="black", width=0)

        # å¦‚æœæ²¡æœ‰ä¸Šä¸€ä¸ªç‚¹çš„ä½ç½®ï¼Œè®°å½•å½“å‰ç‚¹çš„ä½ç½®
        if self.last_x is None or self.last_y is None:
            self.last_x, self.last_y = event.x, event.y
            return

        # ç»˜åˆ¶å½“å‰ç‚¹å’Œä¸Šä¸€ä¸ªç‚¹ä¹‹é—´çš„ç›´çº¿
        self.canvas.create_line(self.last_x, self.last_y, event.x, event.y, fill="black", width=pen_width)
        self.draw.line([self.last_x, self.last_y, event.x, event.y], fill="black", width=pen_width)

        # æ›´æ–°ä¸Šä¸€ä¸ªç‚¹çš„ä½ç½®
        self.last_x, self.last_y = event.x, event.y

    def clear(self):
        # æ¸…ç©ºç”»å¸ƒçš„é€»è¾‘
        self.canvas.delete("all")  # åˆ é™¤ç”»å¸ƒä¸Šçš„æ‰€æœ‰å†…å®¹
        self.image = Image.new("L", (280, 280), "white")  # åˆ›å»ºä¸€ä¸ªæ–°çš„ç™½è‰²èƒŒæ™¯å›¾åƒ
        self.draw = ImageDraw.Draw(self.image)  # åˆ›å»ºä¸€ä¸ªç»˜å›¾å·¥å…·
        self.result_label.config(text="é¢„æµ‹ç»“æœï¼š")  # å°†é¢„æµ‹ç»“æœæ ‡ç­¾é‡ç½®ä¸ºåˆå§‹æ–‡æœ¬
        self.last_x, self.last_y = None, None  # é‡ç½®ä¸Šä¸€ä¸ªç‚¹çš„ä½ç½®

    def preprocess_image(self):
        # è°ƒæ•´å›¾åƒå¤§å°åˆ°28x28å¹¶é¢„å¤„ç†
        image = self.image.resize((28, 28), Image.LANCZOS)  # å°†å›¾åƒå¤§å°è°ƒæ•´ä¸º28x28
        image = np.array(image)  # å°†å›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        
        # åè‰²å¤„ç†ï¼ˆå› ä¸ºè®­ç»ƒæ•°æ®æ˜¯é»‘è‰²èƒŒæ™¯ï¼Œç™½è‰²æ•°å­—ï¼‰
        image = 255 - image  # å°†å›¾åƒåè‰²å¤„ç†
        
        image = image.reshape(1, 28, 28, 1)  # å°†å›¾åƒé‡å¡‘ä¸ºæ¨¡å‹è¾“å…¥çš„å½¢çŠ¶
        image = image / 255.0  # å½’ä¸€åŒ–å¤„ç†
        return image

    def predict(self):
        # é¢„æµ‹æ•°å­—çš„é€»è¾‘
        try:
            image = self.preprocess_image()  # é¢„å¤„ç†å›¾åƒ
            prediction = model.predict(image)  # è°ƒç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
            predicted_digit = np.argmax(prediction)  # è·å–é¢„æµ‹ç»“æœä¸­æ¦‚ç‡æœ€å¤§çš„æ•°å­—
            self.result_label.config(text=f"é¢„æµ‹ç»“æœï¼š{predicted_digit}")  # æ›´æ–°é¢„æµ‹ç»“æœæ ‡ç­¾
        except Exception as e:
            self.result_label.config(text="é¢„æµ‹å¤±è´¥!")
            print("é¢„æµ‹å¤±è´¥:", e)
            traceback.print_exc()

# è¿è¡Œåº”ç”¨ç¨‹åº
if __name__ == "__main__":
    root = tk.Tk()  # åˆ›å»ºä¸»çª—å£
    app = DigitRecognizerApp(root)  # åˆ›å»ºåº”ç”¨ç¨‹åºå®ä¾‹
    root.mainloop()  # å¯åŠ¨äº‹ä»¶å¾ªç¯ï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ


```

éšåï¼Œä½ å¯ä»¥ç›´æ¥è¿è¡Œå®ƒï¼Œæˆ–è€…åœ¨åŒç›®å½•ä¸‹åˆ›å»º`run.bat`ï¼Œè¾“å…¥ä»¥ä¸‹å†…å®¹ï¼š

```cmd
python digit_recognizer_app.py
```

å®é™…è¿è¡Œæ•ˆæœå±•ç¤ºï¼š

![LeNet-5](Image3.png)



## æ€»ç»“

ä½œä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸçš„ `Hello World` é¡¹ç›®ï¼Œ`Digit Recognizer` å¾ˆå¥½åœ°å±•ç¤ºäº†æ·±åº¦å­¦ä¹ çš„åŸºç¡€æµç¨‹ï¼Œæ˜¯å…¥é—¨çš„æœ€ä½³å®è·µã€‚

æ„¿è¯»è€…åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸè¶Šèµ°è¶Šè¿œï¼Œæˆä¸º **DNN** é¢†åŸŸçš„æ–°æ˜Ÿï¼ ğŸš€

## é™„åŠ ï¼šé™„å¸¦å®Œæ•´è¾“å‡ºçš„ä»£ç æ•´åˆ

```python
# å¯¼å…¥æ‰€éœ€çš„åº“
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import MaxPool2D, Conv2D, AveragePooling2D, Flatten, Dense, Dropout, Input

# åŠ è½½æ•°æ®é›†
print("åŠ è½½è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®...")
train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')
print("è®­ç»ƒæ•°æ®å½¢çŠ¶ï¼š", train_data.shape)
print("æµ‹è¯•æ•°æ®å½¢çŠ¶ï¼š", test_data.shape)

# åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
X_train = train_data.drop('label', axis=1).values
y_train = train_data['label'].values
X_test = test_data.values

# æ•°æ®å½’ä¸€åŒ–
print("æ•°æ®å½’ä¸€åŒ–...")
X_train = X_train / 255.0
X_test = X_test / 255.0
print("å½’ä¸€åŒ–åçš„æ•°æ®èŒƒå›´ï¼š", np.min(X_train), "åˆ°", np.max(X_train))

# è°ƒæ•´æ•°æ®å½¢çŠ¶ä»¥é€‚åº”å·ç§¯ç¥ç»ç½‘ç»œ
X_train = X_train.reshape(-1, 28, 28, 1)
X_test = X_test.reshape(-1, 28, 28, 1)
print("è°ƒæ•´åçš„è®­ç»ƒæ•°æ®å½¢çŠ¶ï¼š", X_train.shape)
print("è°ƒæ•´åçš„æµ‹è¯•æ•°æ®å½¢çŠ¶ï¼š", X_test.shape)

# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
print("åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†...")
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)
print("è®­ç»ƒé›†å¤§å°ï¼š", X_train.shape[0])
print("éªŒè¯é›†å¤§å°ï¼š", X_val.shape[0])

# æ„å»ºæ¨¡å‹
print("æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹...")
model = Sequential([
    Input((28, 28, 1)),
    Conv2D(6, (5, 5), activation='sigmoid', padding='valid'),
    AveragePooling2D((2, 2)),
    Conv2D(16, (5, 5), activation='relu', padding='valid'),
    MaxPool2D((2, 2)),
    Flatten(),
    Dense(120, activation='relu'),
    Dropout(0.3),
    Dense(84, activation='relu'),
    Dense(10, activation='softmax')
])

# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
print("æ¨¡å‹ç»“æ„ï¼š")
model.summary()

# è®­ç»ƒæ¨¡å‹
print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
history = model.fit(
    X_train,
    y_train,
    epochs=10,
    batch_size=32,
    validation_data=(X_val, y_val)
)

# å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
print("ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹çš„å‡†ç¡®ç‡å’ŒæŸå¤±æ›²çº¿...")
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.legend()
plt.title('Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training')
plt.plot(history.history['val_loss'], label='Validation')
plt.legend()
plt.title('Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.tight_layout()
plt.show()

# è¯„ä¼°æ¨¡å‹
print("è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½...")
val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
print("éªŒè¯é›†æŸå¤±ï¼š", val_loss)
print("éªŒè¯é›†å‡†ç¡®ç‡ï¼š", val_acc)

# å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
print("å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹...")
predictions = model.predict(X_test)
predicted_labels = np.argmax(predictions, axis=1)

# ç”Ÿæˆæäº¤æ–‡ä»¶
print("ç”Ÿæˆæäº¤æ–‡ä»¶...")
submission = pd.DataFrame({
    'ImageId': range(1, len(predicted_labels) + 1),
    'Label': predicted_labels
})
submission.to_csv('submission.csv', index=False)
print("æäº¤æ–‡ä»¶å·²ä¿å­˜åˆ° submission.csv")

print("è¿è¡Œå®Œæˆï¼")
```

å°†è¿™æ®µä»£ç å¤åˆ¶åˆ°æ–°çš„è®°äº‹æœ¬ä¸­ï¼Œå³å¯ä¸€é”®è®­ç»ƒã€‚
